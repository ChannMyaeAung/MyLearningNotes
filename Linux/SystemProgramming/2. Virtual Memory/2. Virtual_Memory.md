# Virtual Memory

![memory_pyramid](/home/chan/github.com/MyLearningNotes/Linux/SystemProgramming/Virtual Memory/Imgs/memory_pyramid.png)

- Toward the apex of the pyramid, we gain in **Speed** at the cost of size; toward the bottom of the pyramid, it's inverted: **Size** at the cost of speed. 
- We could consider CPU registers to be at the very apex of the pyramid.
- **Swap** is a filesystem type - a raw disk partition is formatted as swap upon system installation. It's treated as second-level RAM by the OS. When the OS runs out of RAM, it uses swap.



- Every single process that is alive will occupy the entire available **virtual address space (VAS)**. Thus, each process overlaps with every other process in terms of VAS.

**Virtual Address Space** : VAS

Virtual page within the process VAS: page

Physical page in RAM: **page frame (pf)**

Does NOT work: **virtual address (va)** -> **physical address (pa)** (maintaining va-to-pa translation entry per address per process is too expensive).

Does Work: (virtual) page -> page frame

- As a rule of thumb, the size of a page is 4 KB (4096 bytes). It's the processor **Memory Management Unit (MMU)** that dictates the page size.
- The mapping process (virtual) page -> page frame is done by the OS on a per-process basis.
- Thus each process has its own mapping table that translates pages to page frames at runtime; it's commonly called the **Paging Table (PT)**.

### Paging Table 

| (Virtual) page | (Physical) page frame |
| -------------- | --------------------- |
| 0              | 3                     |
| 1              | 2                     |
| 2              | 5                     |
| [....]         | [...]                 |
| 15             | 6                     |

- Every process will not use every available page for code or data or whatever; several regions of the virtual address space will remain empty (sparse),
- Even if we do require it, we have a way. When we're out of RAM, we use swap.

| (Virtual) page | (Physical) page frame |
| -------------- | --------------------- |
| 0              | 3                     |
| 1              | 2                     |
| 2              | 5                     |
| [....]         | [...]                 |
| 13             | `<swap-address>`      |
| 14             | `<swap-address>`      |
| 15             | 6                     |

- Each time a process refers to a virtual address, the system must translate the virtual address to the corresponding physical address based on the PTs for that process.



### Address-translation

- At runtime, the process looks up a virtual address which is 9192 bytes from 0, that is, its virtual address: `va = 9192 = 0x000023E8`.

  - If each page is 4096 bytes in size, this implies the va address is on the third page, at an offset of 1000 bytes from the start of that page.
  - With one level of indirection, we have: `va = (page, offset) = (2, 1000)`.
  - The OS sees that the process wants an address in page 2. It does a lookup on the PT for that process, and fins that page 2 maps to page frame 5.

  ```css
  pa = (pf * PAGE_SIZE) + offset
     =  (5 * 4096) + 1000
     =  21480 = 0x000053E8
  ```

  - The system now places the physical address on the bus and the CPU performs its work as usual.

- Another advantage gained by the paging schema is the OS only needs to store a page-to-page-frame mapping.
- The address lookup and translation is done by silicon - the hardware **Memory Management Unit (MMU)** within the CPU!
- The OS is responsible for creating and maintaining PTs for each process.
- The MMU is responsible for performing runtime address-translation (using the OS PTs).

### VM

- **Virtual Memory** is a memory management technique used by modern operating systems that creates an abstraction of a large, continuous memory space for each process, regardless of the actual physical memory (RAM) available. 
- It achieves this by using both the physical RAM and a designated area on disk (often called swap space or a page file) to store data.

#### Key Points:

1. **Abstraction of Memory:**
   - Each process operates in its own virtual address space, which appears contiguous and isolated, even though it may be spread across physical memory and disk.
   - This abstraction simplifies programming since developers do not need to manage the underlying physical memory layout.
2. **Paging/Swapping Mechanism:**
   - The operating system divides memory into fixed-size blocks called **pages**.
   - When the physical memory is full, inactive or less-used pages are moved from RAM to disk (swapped out) to free up space, and pages can be swapped back in when needed.
   - This process, known as **paging**, allows the system to run applications that require more memory than physically available.
3. **Memory Protection and Isolation:**
   - Virtual memory isolates the address space of different processes, ensuring that one process cannot interfere with the memory of another.
   - This isolation enhances system stability and security.

### Why Do We Use Virtual Memory?

1. **Efficient Resource Utilization:**
   - It allows the system to run larger applications and more concurrent processes than would be possible with the available physical RAM alone.
   - By swapping inactive data to disk, the system can dynamically allocate physical memory to processes that need it most.
2. **Simplified Programming:**
   - Developers can work with large, continuous memory spaces without worrying about the physical limitations or fragmentation of RAM.
   - The operating system handles the complexities of mapping virtual addresses to physical locations.
3. **Enhanced Stability and Security:**
   - With separate virtual address spaces, processes are isolated from each other, reducing the risk that a malfunctioning or malicious program could corrupt the memory of other processes or the system.
   - This isolation is crucial for maintaining overall system reliability.
4. **Support for Multitasking:**
   - Virtual memory allows multiple processes to run concurrently by managing their memory needs efficiently, even when the sum of their memory requirements exceeds the available physical memory.

### Benefits of VMs

At first glance, the sheer overhead introduced due to virtual memory and the associated address-translation would seem to warrant not using it.

The overhead is high, but the reality is:

- Modern hardware-acceleration (via TLBs/CPU caches/prefetching) mitigates this overhead and provides decent enough performance.
- The benefits one derives from VM outweigh the performance issues.

On a VM-based system, we get the following benefits:

- Process-isolation
- demand paging
- copy-on-write (COW) handling
- defragmentation
- memory overcommit
- memory-compaction
- Kernel Samepage Merging (KSM)
- Transcendent Memory (TM)
- The programmer need not worry about physical memory
- Memory-region protection

#### Memory-region protection

- We can set certain protections on certain pages such as read, write, execute permissions, but what if an application disobeys them?
- On a VM-enabled system, the OS - the MMU - is able to tap into every single memory access and determine whether the end user process is obeying the rules or not.
  - If it is, the access proceeds successfully.
  - If not, the MMU hardware raises an exception (similar, but not identical, to an interrupt).
  - The OS now jumps into a code routine called the exception hanlder.
  - The OS exception-handling routine determines whether the access is indeed illegal, and if so, the OS immediately kills the process attempting this illegal access.
  - In fact, this is pretty much exactly what a Segmentation Violation or segfault is.