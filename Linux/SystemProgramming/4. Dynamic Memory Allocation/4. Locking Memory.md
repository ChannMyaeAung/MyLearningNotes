# Locking memory

- On a virtual memory-based OS, such as Linux, a usermode page can be swapped at any point in time. The Linux kernel memory management code makes these decisions.
- To the regular application process, this should not matter.
  - Any time it attempts to access (read, write or execute) the page content, the kernel will page it back into RAM, and allow it to use it as though nothing had occurred.
  - This handling is generally called **servicing a page fault** and is completely transparent to the usermode application process.
- However, there are some situations where memory pages being paged - written from RAM to swap and vice-versa - is undesireable.
  - Realtime applications
  - Cryptography (security) applications
- Imagine that the **real-time process is executing a critical code path** and a data page has to be paged in from the swap partition at that moment, the latency introduced could ruin the application's characteristics, resulting in dismal failure.
  - In these cases, developers need a way to guarantee that said pages of memory can guaranteed to be resident in RAM, thus avoiding any page faulting.
- In some types of **security** applications, they would likely store some secrets in memory (a password, a key).
  - If the memory pages containing these are written out to disk (swap), there is always the possibility that it remains on disk well after the application exits, resulting in what;s called **information leakage**, which is a bug attackers are just waiting to pounce upon.
  - The need of the hour is to guarantee that those pages cannot be swapped out.

---

## `mlock(2)`

- The `mlock(2)` (`mlock2` and `mlockall`) system calls; the express purpose of these APIs is to lock memory pages withing the calling process's virtual address space.

```c
int mlock(const void *addr, size_t len);
```

- `addr` is a pointer to the (virtual) memory region to lock.
- `len` is the number of bytes to lock into RAM.

#### Code

```c
int main()
{
    size_t size = getpagesize();
    char *buffer = malloc(size);
    if (!buffer)
    {
        perror("malloc");
        exit(EXIT_FAILURE);
    }

    if (mlock(buffer, size) != 0)
    {
        perror("mlock");
        free(buffer);
        exit(EXIT_FAILURE);
    }

    printf("Memory locked.\n");

    // Unlock the memory before exit
    if (munlock(buffer, size) != 0)
    {
        perror("munlock");
    }

    free(buffer);
    return 0;
}
```

#### Output

```sh
chan@CMA:~/C_Programming/test$ make valgrind
valgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./final
==14862== Memcheck, a memory error detector
==14862== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.
==14862== Using Valgrind-3.22.0 and LibVEX; rerun with -h for copyright info
==14862== Command: ./final
==14862== 
Memory locked.
==14862== 
==14862== HEAP SUMMARY:
==14862==     in use at exit: 0 bytes in 0 blocks
==14862==   total heap usage: 2 allocs, 2 frees, 5,120 bytes allocated
==14862== 
==14862== All heap blocks were freed -- no leaks are possible
==14862== 
==14862== For lists of detected and suppressed errors, rerun with: -s
==14862== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```

---

## Locking all pages

- `mlock` basically allows us to tell the OS to lock a certain range of memory into RAM.
- In some real-world cases, we cannot predict exactly which pages of memory we will require resident in advance (a real-time application might require various, or all, memory pages to always be resident).
- To solve this issue, another system call `mlockall(2)` exists. It allows us to lock all process memory pages.

```c
int mlockall(int flags);
```

- If successful, all the process's memory pages, such as text, data segments, library pages, stack, and shared memory segments are guaranteed to remain resident in RAM until unlocked.
- The `flags` argument provides further control to the application developer. It can be bitwise OR of the following:
  - `MCL_CURRENT`
    - Using `MCL_CURRENT`  asks the OS to lock all current pages within the calling process's VAS into memory.
  - `MCL_FUTURE`
    - What if we issue the `mlockall(2)` system call at initialization time, but the real-time process is going to perform an `malloc` of say, 200 kilobytes, 5 minutes from now? 
    - We need to guarantee that those 200 KB of memory (which is 50 pages, given a 4 KB page size) is always resident in RAM (otherwise, the real-time application will suffer too great a latency from possible future page faulting). 
    - That is the purpose of the `MCL_FUTURE` flag: it guarantees the memory pages that become part of the calling process's VAS in the future will remain resident in memory until unlocked.
  - `MCL_ONFAULT`
    - Performing `malloc` does nothing more than reserve virtual memory, not physical. 
    - As an example, if an (non-real-time) application performs a rather large allocation of a megabyte (that's 512 pages), we understand that only 512 virtual pages are reserved and the physical page frames are not actually allocated
    - They will get faulted in on-demand. A typical realtime application will therefore need to somehow guarantee that, once faulted in, these 512 pages will remain locked (resident) in RAM.
    - We can use the `MCL_ONFAULT` flag to achieve
      this.
- This flag must be used in conjunction with either the `MCL_CURRENT` or `MCL_FUTURE` flag, or both.
- The idea is that physical memory consumption remains extremely efficient (as no physical allocation is done at the time of `malloc`), and yet, once the application starts to touch the virtual pages (that is read, write or execute data or code within the page), the physical page frames get faulted in and they will then be locked.
  - In other words, we do not pre-fault the memory, thus we get the best of both worlds.
- When done, the application can unlock all memory pages by issuing the counterpart API: `munlockall(2)`.
